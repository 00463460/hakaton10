<!--
SYNC IMPACT REPORT
Version Change: Initial â†’ 1.0.0
Modified Principles: N/A (Initial version)
Added Sections: All core principles, Technology Stack, Quality Standards, Development Workflow, Governance
Removed Sections: None
Templates Requiring Updates:
  âœ… constitution.md created
  âš  plan-template.md - pending alignment validation
  âš  spec-template.md - pending alignment validation
  âš  tasks-template.md - pending alignment validation
Follow-up TODOs: None
-->

# Physical AI & Humanoid Robotics Textbook Constitution

## Core Principles

### I. Specification Primacy
All code, content, and architecture decisions MUST strictly follow specifications and plans generated by Spec-Kit Plus. No implementation work begins without approved specifications. Every feature must have:
- A complete spec.md defining requirements and acceptance criteria
- A plan.md detailing architectural decisions and technical approach
- A tasks.md breaking down implementation into testable units

**Rationale**: Prevents scope creep, ensures traceability, and maintains alignment between stakeholder intent and delivered artifacts.

### II. Free-Tier Architecture
The entire technical stack MUST rely exclusively on free-tier services to ensure zero recurring costs and hackathon eligibility:
- **Vector Database**: Qdrant Cloud Free Tier (1GB storage, 100k vectors)
- **Relational Database**: Neon Serverless Postgres Free Tier (0.5GB storage, 100 hours compute/month)
- **Deployment**: GitHub Pages (static hosting)
- **LLM/Embeddings**: OpenAI API with cost controls OR free-tier alternatives if cost-prohibitive

**Rationale**: Ensures project sustainability, reproducibility for educational use, and hackathon compliance.

### III. RAG Security and Accuracy
The RAG chatbot MUST exclusively answer questions based on vectorized textbook content. It MUST NOT hallucinate or generate content outside the knowledge base:
- All embeddings derive from approved textbook chapters (MDX source)
- Queries must return source citations with chapter/section references
- User-selected text on page must be supported as context for RAG queries
- Responses must include confidence scores and source attribution

**Rationale**: Academic integrity requires factual accuracy; students must trace answers back to authoritative textbook sections.

### IV. High-Performance UX
The Docusaurus site MUST deliver sub-2-second page loads and deploy without manual intervention:
- Lighthouse Performance score â‰¥ 90 on production deployment
- GitHub Actions CI/CD pipeline for automated deployments to GitHub Pages
- Mobile-responsive design (tested on 320pxâ€“1920px viewports)
- Accessible (WCAG 2.1 Level AA compliance)

**Rationale**: User engagement correlates directly with site performance; slow load times undermine educational effectiveness.

### V. Technical Precision and Clarity
All textbook content MUST be technically accurate, using industry-standard notation and tooling:
- Mathematical equations rendered via LaTeX (using KaTeX or MathJax in Docusaurus)
- Code examples executable without modification (tested via CI)
- MDX format for all chapters (enables React component integration)
- Diagrams generated programmatically (Mermaid.js) or vector formats (SVG)

**Rationale**: Engineering students require precision; ambiguous notation or untested code erodes trust and pedagogical value.

### VI. Test-First for Code (NON-NEGOTIABLE)
All Python/FastAPI backend code MUST follow TDD discipline:
- Tests written â†’ User approved â†’ Tests fail â†’ Implement â†’ Tests pass
- Minimum 80% code coverage (pytest-cov)
- Integration tests for RAG pipeline (embedding â†’ retrieval â†’ generation)
- No untested code merged to main branch

**Rationale**: Prevents regressions in critical RAG and auth workflows; ensures refactoring safety.

### VII. Modular Content Architecture
Textbook content MUST align with the 4-module course structure and support reusable components:
- **Module 1**: Introduction to Physical AI & Humanoid Robotics (Week 1-2)
- **Module 2**: ROS 2 Fundamentals & Simulation with Isaac Sim (Week 3-6)
- **Module 3**: Vision-Language-Action Models & AI Integration (Week 7-10)
- **Module 4**: Advanced Topics: Kinematics, Control, and Real-World Deployment (Week 11-14)

Each module must:
- Be independently readable (minimal forward references)
- Include practice exercises with solutions (hidden behind collapsible sections)
- Provide code examples in both Python (primary) and C++ (where performance-critical)

**Rationale**: Students may enter the course at different skill levels; modularity enables flexible learning paths.

### VIII. Reusable Intelligence via Subagents
Define and utilize three core subagent types to maximize hackathon bonus points:
1. **Code Subagent**: Generates and reviews FastAPI endpoints, RAG logic, and database schemas
2. **Content Subagent**: Drafts/refines textbook chapters, ensures LaTeX correctness, validates technical accuracy
3. **Utility Subagent**: Handles repetitive tasks (file structure generation, MDX linting, deployment scripts)

All subagents MUST:
- Be invoked via Claude Code's Task tool with explicit subagent_type
- Log invocations to track reuse metrics for hackathon judging
- Produce auditable outputs (PHRs for significant decisions)

**Rationale**: Demonstrates advanced AI-SD engineering practices; subagent reuse is a hackathon evaluation criterion.

## Technology Stack Decisions

### Frontend & Deployment
- **Framework**: Docusaurus v3 (React 18, MDX 2)
- **Styling**: Custom CSS modules + Infima (Docusaurus default theme)
- **Deployment**: GitHub Pages via `gh-pages` branch
- **CI/CD**: GitHub Actions (build â†’ test â†’ deploy on push to main)

### Backend & APIs
- **Framework**: FastAPI (Python 3.11+)
- **RAG Pipeline**: LangChain + OpenAI Embeddings (text-embedding-3-small) + Qdrant vector store
- **Authentication**: Better-Auth (email/password) with Neon Postgres session storage
- **API Documentation**: Automatic via FastAPI's OpenAPI integration (Swagger UI at `/docs`)

### Data Layer
- **Vector Database**: Qdrant Cloud Free Tier (managed, HTTP API)
- **Relational Database**: Neon Serverless Postgres (for users, sessions, metadata)
- **Content Source**: MDX files in `docs/` directory (versioned in Git)

### Development Tools
- **Package Management**: pnpm (frontend), Poetry (backend)
- **Testing**: Vitest (frontend), pytest (backend)
- **Linting**: ESLint + Prettier (JS/TS), Ruff (Python)
- **Type Checking**: TypeScript strict mode, mypy (Python)

## Quality Standards

### Code Quality
- **Python**: Follow PEP 8, type hints mandatory, docstrings for public APIs (Google style)
- **TypeScript/JavaScript**: Airbnb style guide, strict TypeScript, JSDoc for complex functions
- **MDX**: Frontmatter schema validation, LaTeX syntax checking via CI

### Performance Budgets
- **Page Load**: First Contentful Paint < 1.5s, Time to Interactive < 2.5s
- **API Latency**: RAG query p95 < 3s, authentication p95 < 500ms
- **Bundle Size**: Initial JS bundle < 200KB gzipped

### Security Requirements
- **Authentication**: Bcrypt password hashing (cost factor â‰¥ 12), HTTP-only cookies for sessions
- **API**: CORS restricted to GitHub Pages domain, rate limiting (10 req/min per IP for RAG)
- **Secrets**: Environment variables only, never commit to Git, use GitHub Secrets for CI/CD
- **Input Validation**: Pydantic models for all API inputs, sanitize user-selected text before RAG queries

### Accessibility (WCAG 2.1 AA)
- Semantic HTML, ARIA labels for interactive elements
- Keyboard navigation for all features (chatbot, auth forms, content personalization)
- Color contrast ratio â‰¥ 4.5:1, focus indicators visible

## Development Workflow

### Feature Development Cycle
1. **Specify**: Run `/sp.specify` with feature description â†’ generates `specs/<feature>/spec.md`
2. **Plan**: Run `/sp.plan` â†’ generates `specs/<feature>/plan.md` with architectural decisions
3. **Task Breakdown**: Run `/sp.tasks` â†’ generates `specs/<feature>/tasks.md` with testable units
4. **Implement**: TDD loop (Red â†’ Green â†’ Refactor), run `/sp.implement` for automated execution
5. **Review**: Code review via PR, ensure PHR exists for significant decisions
6. **Deploy**: Merge to main â†’ GitHub Actions deploys to GitHub Pages

### Architectural Decision Records (ADRs)
When planning/implementing features, detect significance via three-part test:
- **Impact**: Does this decision have long-term consequences? (e.g., framework choice, data model, API contract)
- **Alternatives**: Were multiple viable options considered?
- **Scope**: Is the decision cross-cutting (affects multiple modules/layers)?

If ALL are true, suggest ADR creation:
```
ðŸ“‹ Architectural decision detected: [brief description]
   Document reasoning and tradeoffs? Run `/sp.adr [decision-title]`
```

Never auto-create ADRs; require user consent. Store ADRs in `history/adr/` with format: `NNNN-decision-title.md`.

### Prompt History Records (PHRs)
MUST create PHR after every user interaction involving:
- Implementation work (code/content changes)
- Planning/architecture discussions
- Spec/task/plan creation
- Debugging sessions

PHR routing (all under `history/prompts/`):
- Constitution â†’ `history/prompts/constitution/`
- Feature stages (spec, plan, tasks, red, green, refactor, explainer, misc) â†’ `history/prompts/<feature-name>/`
- General â†’ `history/prompts/general/`

PHR filename format: `<ID>-<slug>.<stage>.prompt.md` (e.g., `001-setup-docusaurus.spec.prompt.md`)

### Version Control Strategy
- **Main Branch**: Production-ready, protected, requires PR approval
- **Feature Branches**: `feature/<feature-name>` naming convention
- **Commit Messages**: Conventional Commits (feat:, fix:, docs:, test:, refactor:)
- **Tags**: Semantic versioning (v1.0.0) for textbook releases

## Governance

### Constitutional Amendments
- Amendments require documentation of rationale and impact analysis
- Version bumping rules:
  - **MAJOR**: Backward-incompatible principle removals/redefinitions
  - **MINOR**: New principles or materially expanded guidance
  - **PATCH**: Clarifications, wording fixes, non-semantic refinements
- All PRs/reviews must verify constitutional compliance
- Run `/sp.constitution` to update this document; ensure dependent templates synced

### Compliance Enforcement
- Every spec.md MUST reference relevant constitutional principles
- Every plan.md MUST justify architectural decisions against principles (or document exceptions)
- Every tasks.md MUST include acceptance criteria aligned with quality standards
- CI pipeline gates:
  - Linting (code quality)
  - Test coverage â‰¥ 80%
  - Lighthouse Performance â‰¥ 90
  - No hardcoded secrets (detect via git-secrets or Gitleaks)

### Complexity Justification
Any deviation from simplicity (YAGNI principle) MUST be justified in ADR or plan.md:
- Adding abstraction layers â†’ justify with concrete reuse cases
- Introducing new dependencies â†’ justify with cost-benefit analysis (bundle size, maintenance burden)
- Performance optimizations â†’ justify with benchmarks showing measurable improvement

### Runtime Guidance
For day-to-day development, refer to:
- `CLAUDE.md` for agent-specific execution contract
- `README.md` for project setup and contribution guidelines
- `.specify/templates/` for spec/plan/task formatting standards

**Version**: 1.0.0 | **Ratified**: 2025-12-12 | **Last Amended**: 2025-12-12
